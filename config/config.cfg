[Paths]
chroma_db = data/chroma_db
sqlite_db = data/urls_to_ingest.db
llm_model = models/Phi-3-mini-4k-instruct-q4.gguf
embedding_model = models/mxbai-embed-large-v1-f16.gguf

[ChromaDB]
collection_name = fetch_collection

[Models]
# Parameters for LLM initialization (rag_query.py)
n_ctx = 4096 # Context length
n_threads = 8 # Number of threads for inference

[RAG]
# Number of chunks to retrieve for context (rag_query.py)
similarity_k = 3

[Logging]
level = INFO

[Scraping]
# Timeout for HTTP requests (web_scraping.py)
timeout = 15
# Minimum length to consider content as valid (web_scraping.py)
min_content_length = 100